{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM with validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, CuDNNLSTM, Embedding, Dropout, Activation, Flatten, Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model, Sequential\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.layers import LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55328\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  is_sarcastic\n",
       "0  former versace store clerk sues over secret 'b...             0\n",
       "1  the 'roseanne' revival catches up to our thorn...             0\n",
       "2  mom starting to fear son's web series closest ...             1\n",
       "3  boehner just wants wife to listen, not come up...             1\n",
       "4  j.k. rowling wishes snape happy birthday in th...             0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_json(\"./data/Sarcasm_Headlines_Dataset.json\", lines=True)\n",
    "df2 = pd.read_json(\"./data/Sarcasm_Headlines_Dataset_v2.json\", lines=True)\n",
    "# re-order attibute columns in df2\n",
    "df2 = df2[['article_link','headline','is_sarcastic']]\n",
    "df = pd.concat([df1, df2], axis=0)\n",
    "df = df.drop(['article_link'], axis=1)\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset the index as we have merged two different indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.953368999421631\n",
      "2\n",
      "151\n"
     ]
    }
   ],
   "source": [
    "df['len'] = df['headline'].apply(lambda x: len(x.split(\" \")))\n",
    "print(df['len'].mean())\n",
    "print(min(df['len']))\n",
    "print(max(df['len']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data in train, test and val\n",
    "50% for train, 25% for test, 25% for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41496, 3)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size=0.25)\n",
    "print(train.shape)\n",
    "train, val = train_test_split(train, test_size=0.33333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (27664, 3)\n",
      "test: (13832, 3)\n",
      "val: (13832, 3)\n"
     ]
    }
   ],
   "source": [
    "print('train:',train.shape)\n",
    "print('test:',test.shape)\n",
    "print('val:',val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize\n",
    "Fit the tokenizer only on the text of training data.\n",
    "Then, we use that same tokenizer to transform the texts of train, val and test sets to sequences of integers.\n",
    "\n",
    "It's possible to fit on the entire data. But it's probably a better idea to reserve a token for \"unknown\" words (oov_token=True), for the cases when you find new test data with words your model has never seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000 # max num words\n",
    "maxlen = 25 # we could also try 151\n",
    "embedding_size = 200\n",
    "\n",
    "# create the tokenizer with the maximum number of words to keep, \n",
    "# based on word frequency. \n",
    "# Only the most common num_words-1 words will be kept.\n",
    "tokenizer = Tokenizer(num_words=max_features, oov_token = True)\n",
    "\n",
    "# fit the tokenizer on the headlines\n",
    "tokenizer.fit_on_texts(list(train['headline']))\n",
    "\n",
    "# Transforms each text in texts to a sequence of integers.\n",
    "train_X = tokenizer.texts_to_sequences(train['headline'])\n",
    "test_X = tokenizer.texts_to_sequences(test['headline'])\n",
    "val_X = tokenizer.texts_to_sequences(val['headline'])\n",
    "\n",
    "# transforms a list of num_samples sequences (lists of integers)\n",
    "# into a 2D Numpy array of shape (num_samples, num_timesteps).\n",
    "train_X = pad_sequences(train_X, maxlen = maxlen)\n",
    "test_X = pad_sequences(test_X, maxlen = maxlen)\n",
    "val_X = pad_sequences(val_X, maxlen = maxlen)\n",
    "\n",
    "train_y = train['is_sarcastic']\n",
    "test_y = test['is_sarcastic']\n",
    "val_y = val['is_sarcastic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load glove embedding set, construct embedding matrix for words in word_index:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elsas\\Anaconda3\\envs\\TFM\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3254: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "# load embeddings\n",
    "EMBEDDING_FILE = './embeddings/glove.6B.200d.txt'\n",
    "\n",
    "def get_coefs(word,*arr): \n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "# first, build index mapping words in the embeddings set\n",
    "# to their embedding vector\n",
    "embeddings_index = {}\n",
    "with open(EMBEDDING_FILE, encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = get_coefs(*line.split(\" \"))\n",
    "        embeddings_index[word] = coefs\n",
    "            \n",
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "\n",
    "# Random embedding vector for unknown words.\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embedding_size))\n",
    "# prepare embedding matrix\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: \n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: \n",
    "        # words not found in embedding index will be random\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Model\n",
    "Model Parameters:\n",
    "\n",
    "- **Activation Function**: I have used ReLU as the activation function. ReLU is a non-linear activation function, which helps complex relationships in the data to be captured by the model.\n",
    "\n",
    "- **Optimiser**: We use adam optimiser, which is an adaptive learning rate optimiser.\n",
    "\n",
    "- **Loss function**: We will train a network to output a probability over the 2 classes using Sigmoid Loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model structure\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_size, weights = [embedding_matrix]))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences = True)))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(40, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(20, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',keras.metrics.Precision(), keras.metrics.Recall(), keras.metrics.TruePositives()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the best model and early stopping\n",
    "To prevent the model from overfitting I have enabled early stopping.\n",
    "\n",
    "Early stopping is a method that allows us to specify an arbitrary large number of training epochs and stop training once the model performance stops improving on a hold out/validation dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model after every epoch.\n",
    "saveBestModel = keras.callbacks.ModelCheckpoint('./model/best_model.hdf5', monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "# Stop training when a monitored quantity has stopped improving.\n",
    "earlyStopping = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elsas\\Anaconda3\\envs\\TFM\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27664 samples, validate on 13832 samples\n",
      "Epoch 1/25\n",
      "27664/27664 [==============================] - 52s 2ms/step - loss: 0.5504 - accuracy: 0.6950 - precision_1: 0.6927 - recall_1: 0.6068 - true_positives_1: 7729.0000 - val_loss: 0.3134 - val_accuracy: 0.8643 - val_precision_1: 0.8371 - val_recall_1: 0.8747 - val_true_positives_1: 5555.0000\n",
      "Epoch 2/25\n",
      "  100/27664 [..............................] - ETA: 44s - loss: 0.4303 - accuracy: 0.8400 - precision_1: 0.7917 - recall_1: 0.8636 - true_positives_1: 38.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elsas\\Anaconda3\\envs\\TFM\\lib\\site-packages\\keras\\callbacks\\callbacks.py:707: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27664/27664 [==============================] - 50s 2ms/step - loss: 0.2931 - accuracy: 0.8951 - precision_1: 0.8814 - recall_1: 0.8922 - true_positives_1: 11364.0000 - val_loss: 0.2470 - val_accuracy: 0.8989 - val_precision_1: 0.8906 - val_recall_1: 0.8892 - val_true_positives_1: 5647.0000\n",
      "Epoch 3/25\n",
      "27664/27664 [==============================] - 51s 2ms/step - loss: 0.1749 - accuracy: 0.9414 - precision_1: 0.9365 - recall_1: 0.9362 - true_positives_1: 11925.0000 - val_loss: 0.2385 - val_accuracy: 0.9163 - val_precision_1: 0.9054 - val_recall_1: 0.9131 - val_true_positives_1: 5799.0000\n",
      "Epoch 4/25\n",
      "14600/27664 [==============>...............] - ETA: 21s - loss: 0.1078 - accuracy: 0.9660 - precision_1: 0.9622 - recall_1: 0.9633 - true_positives_1: 6423.0000"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "batch_size = 100\n",
    "epochs = 25\n",
    "model.fit(train_X, train_y, batch_size=batch_size, epochs=epochs, validation_data=(val_X, val_y), callbacks=[saveBestModel, earlyStopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stops in the Epoch 6 out of 25, this is thanks to the validation set, that prevents us to overfit the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model results with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy, precision, recall, true_positives = model.evaluate(test_X, test_y, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_pr=precision*recall\n",
    "sum_pr=precision+recall\n",
    "div=mult_pr/sum_pr\n",
    "f1_score=2*div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss, Accuracy, Precision, Recall and F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loss:',loss)\n",
    "print('Accuracy:',accuracy)\n",
    "print('Precision:',precision)\n",
    "print('Recall:',recall)\n",
    "print('f1 score:',f1_score)\n",
    "print('True positives:',true_positives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract FalsePositives and FalseNegatives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first get the list of predictions. In the confusion matrix it can be observed that the number of True Positives is the same ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = model.predict_classes(test_X, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7198,  386],\n",
       "       [ 697, 5551]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFalsePositive(test_X, test_y, pred_y):\n",
    "    FP_text = []\n",
    "    FP_index = []\n",
    "    for i in range(len(test_y)):\n",
    "        if(pred_y[i]==1 and test_y[i]==0):\n",
    "            FP_text.append(test_X[i])\n",
    "            FP_index.append(test_y.index[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26007</th>\n",
       "      <td>a good news story about 'imperfect' pregnancy</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11141</th>\n",
       "      <td>leaving your dream: tedx talk</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28929</th>\n",
       "      <td>turkish soccer body penalizes kurdish club ami...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37367</th>\n",
       "      <td>listen up, girlfriends: we need each other</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32993</th>\n",
       "      <td>u.s. reaches major milestone: 100,000 american...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47161</th>\n",
       "      <td>looking through the glass ceiling</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14338</th>\n",
       "      <td>move over 'hamilton,' d.c. just debuted 'trump'</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22755</th>\n",
       "      <td>kimmel, atop scorched earth, takes aim at trum...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50715</th>\n",
       "      <td>these newlyweds have god-like locks and the in...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8246</th>\n",
       "      <td>does a reasonable worker lactate?</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13832 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                headline  is_sarcastic  len\n",
       "26007      a good news story about 'imperfect' pregnancy             0    7\n",
       "11141                      leaving your dream: tedx talk             0    5\n",
       "28929  turkish soccer body penalizes kurdish club ami...             0    9\n",
       "37367         listen up, girlfriends: we need each other             0    7\n",
       "32993  u.s. reaches major milestone: 100,000 american...             0   10\n",
       "...                                                  ...           ...  ...\n",
       "47161                  looking through the glass ceiling             0    5\n",
       "14338    move over 'hamilton,' d.c. just debuted 'trump'             0    7\n",
       "22755  kimmel, atop scorched earth, takes aim at trum...             0   12\n",
       "50715  these newlyweds have god-like locks and the in...             0   12\n",
       "8246                   does a reasonable worker lactate?             0    5\n",
       "\n",
       "[13832 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28929    turkish soccer body penalizes kurdish club ami...\n"
     ]
    }
   ],
   "source": [
    "print(test.loc[[28929]]['headline'].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([26007, 11141, 28929, 37367, 32993, 15828, 28978,   949, 37359,\n",
      "            27498,\n",
      "            ...\n",
      "            31382, 49606, 28532, 52197, 17760, 47161, 14338, 22755, 50715,\n",
      "             8246],\n",
      "           dtype='int64', length=13832)\n"
     ]
    }
   ],
   "source": [
    "print(test.index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
