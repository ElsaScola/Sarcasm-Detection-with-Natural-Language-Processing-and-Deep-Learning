{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM with validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, CuDNNLSTM, Embedding, Dropout, Activation, Flatten, Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model, Sequential\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.layers import LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55328\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  is_sarcastic\n",
       "0  former versace store clerk sues over secret 'b...             0\n",
       "1  the 'roseanne' revival catches up to our thorn...             0\n",
       "2  mom starting to fear son's web series closest ...             1\n",
       "3  boehner just wants wife to listen, not come up...             1\n",
       "4  j.k. rowling wishes snape happy birthday in th...             0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_json(\"./data/Sarcasm_Headlines_Dataset.json\", lines=True)\n",
    "df2 = pd.read_json(\"./data/Sarcasm_Headlines_Dataset_v2.json\", lines=True)\n",
    "# re-order attibute columns in df2\n",
    "df2 = df2[['article_link','headline','is_sarcastic']]\n",
    "df = pd.concat([df1, df2], axis=0)\n",
    "df = df.drop(['article_link'], axis=1)\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset the index as we have merged two different indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.953368999421631\n",
      "2\n",
      "151\n"
     ]
    }
   ],
   "source": [
    "df['len'] = df['headline'].apply(lambda x: len(x.split(\" \")))\n",
    "print(df['len'].mean())\n",
    "print(min(df['len']))\n",
    "print(max(df['len']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data in train, test and val\n",
    "50% for train, 25% for test, 25% for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41496, 3)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size=0.25)\n",
    "print(train.shape)\n",
    "train, val = train_test_split(train, test_size=0.33333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (27664, 3)\n",
      "test: (13832, 3)\n",
      "val: (13832, 3)\n"
     ]
    }
   ],
   "source": [
    "print('train:',train.shape)\n",
    "print('test:',test.shape)\n",
    "print('val:',val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize\n",
    "Fit the tokenizer only on the text of training data.\n",
    "Then, we use that same tokenizer to transform the texts of train, val and test sets to sequences of integers.\n",
    "\n",
    "It's possible to fit on the entire data. But it's probably a better idea to reserve a token for \"unknown\" words (oov_token=True), for the cases when you find new test data with words your model has never seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000 # max num words\n",
    "maxlen = 25 # we could also try 151\n",
    "embedding_size = 200\n",
    "\n",
    "# create the tokenizer with the maximum number of words to keep, \n",
    "# based on word frequency. \n",
    "# Only the most common num_words-1 words will be kept.\n",
    "tokenizer = Tokenizer(num_words=max_features, oov_token = True)\n",
    "\n",
    "# fit the tokenizer on the headlines\n",
    "tokenizer.fit_on_texts(list(train['headline']))\n",
    "\n",
    "# Transforms each text in texts to a sequence of integers.\n",
    "train_X = tokenizer.texts_to_sequences(train['headline'])\n",
    "test_X = tokenizer.texts_to_sequences(test['headline'])\n",
    "val_X = tokenizer.texts_to_sequences(val['headline'])\n",
    "\n",
    "# transforms a list of num_samples sequences (lists of integers)\n",
    "# into a 2D Numpy array of shape (num_samples, num_timesteps).\n",
    "train_X = pad_sequences(train_X, maxlen = maxlen)\n",
    "test_X = pad_sequences(test_X, maxlen = maxlen)\n",
    "val_X = pad_sequences(val_X, maxlen = maxlen)\n",
    "\n",
    "train_y = train['is_sarcastic']\n",
    "test_y = test['is_sarcastic']\n",
    "val_y = val['is_sarcastic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load glove embedding set, construct embedding matrix for words in word_index:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elsas\\Anaconda3\\envs\\TFM\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3254: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "# load embeddings\n",
    "EMBEDDING_FILE = './embeddings/glove.6B.200d.txt'\n",
    "\n",
    "def get_coefs(word,*arr): \n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "# first, build index mapping words in the embeddings set\n",
    "# to their embedding vector\n",
    "embeddings_index = {}\n",
    "with open(EMBEDDING_FILE, encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = get_coefs(*line.split(\" \"))\n",
    "        embeddings_index[word] = coefs\n",
    "            \n",
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "\n",
    "# Random embedding vector for unknown words.\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embedding_size))\n",
    "# prepare embedding matrix\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: \n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: \n",
    "        # words not found in embedding index will be random\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Model\n",
    "Model Parameters:\n",
    "\n",
    "- **Activation Function**: I have used ReLU as the activation function. ReLU is a non-linear activation function, which helps complex relationships in the data to be captured by the model.\n",
    "\n",
    "- **Optimiser**: We use adam optimiser, which is an adaptive learning rate optimiser.\n",
    "\n",
    "- **Loss function**: We will train a network to output a probability over the 2 classes using Sigmoid Loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model structure\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_size, weights = [embedding_matrix]))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences = True)))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(40, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(20, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',keras.metrics.Precision(), keras.metrics.Recall(), keras.metrics.TruePositives()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the best model and early stopping\n",
    "To prevent the model from overfitting I have enabled early stopping.\n",
    "\n",
    "Early stopping is a method that allows us to specify an arbitrary large number of training epochs and stop training once the model performance stops improving on a hold out/validation dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model after every epoch.\n",
    "saveBestModel = keras.callbacks.ModelCheckpoint('./model/best_model.hdf5', monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "# Stop training when a monitored quantity has stopped improving.\n",
    "earlyStopping = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elsas\\Anaconda3\\envs\\TFM\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27664 samples, validate on 13832 samples\n",
      "Epoch 1/25\n",
      "27664/27664 [==============================] - 57s 2ms/step - loss: 0.5658 - accuracy: 0.6983 - precision_1: 0.7017 - recall_1: 0.5904 - true_positives_1: 7460.0000 - val_loss: 0.3389 - val_accuracy: 0.8558 - val_precision_1: 0.8222 - val_recall_1: 0.8742 - val_true_positives_1: 5537.0000\n",
      "Epoch 2/25\n",
      "  100/27664 [..............................] - ETA: 48s - loss: 0.3532 - accuracy: 0.9200 - precision_1: 0.9123 - recall_1: 0.9455 - true_positives_1: 52.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elsas\\Anaconda3\\envs\\TFM\\lib\\site-packages\\keras\\callbacks\\callbacks.py:707: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27664/27664 [==============================] - 55s 2ms/step - loss: 0.3198 - accuracy: 0.8861 - precision_1: 0.8537 - recall_1: 0.9057 - true_positives_1: 11444.0000 - val_loss: 0.2818 - val_accuracy: 0.8879 - val_precision_1: 0.8887 - val_recall_1: 0.8633 - val_true_positives_1: 5468.0000 0.9047 - true_positives - ETA: 2s - loss: 0.3204 - accuracy: 0.8852 - precision_1: 0.8526 - recall_1: 0.9054 - true_positives_1: 1093 - ETA: 1s - loss: 0.3199 - accuracy: 0.8851 - precision_1: 0.8528 - recall_1: 0.9050 - true_pos\n",
      "Epoch 3/25\n",
      "27664/27664 [==============================] - 59s 2ms/step - loss: 0.2075 - accuracy: 0.9337 - precision_1: 0.9103 - recall_1: 0.9482 - true_positives_1: 11980.0000 - val_loss: 0.2792 - val_accuracy: 0.9039 - val_precision_1: 0.8962 - val_recall_1: 0.8937 - val_true_positives_1: 5661.0000\n",
      "Epoch 4/25\n",
      "27664/27664 [==============================] - 62s 2ms/step - loss: 0.1359 - accuracy: 0.9581 - precision_1: 0.9435 - recall_1: 0.9662 - true_positives_1: 12208.0000 - val_loss: 0.2739 - val_accuracy: 0.9112 - val_precision_1: 0.8891 - val_recall_1: 0.9211 - val_true_positives_1: 5834.0000\n",
      "Epoch 5/25\n",
      "27664/27664 [==============================] - 68s 2ms/step - loss: 0.0865 - accuracy: 0.9736 - precision_1: 0.9640 - recall_1: 0.9788 - true_positives_1: 12367.0000 - val_loss: 0.3418 - val_accuracy: 0.9155 - val_precision_1: 0.8968 - val_recall_1: 0.9215 - val_true_positives_1: 5837.0000\n",
      "Epoch 6/25\n",
      "27664/27664 [==============================] - 68s 2ms/step - loss: 0.0619 - accuracy: 0.9835 - precision_1: 0.9797 - recall_1: 0.9843 - true_positives_1: 12436.0000 - val_loss: 0.4500 - val_accuracy: 0.9187 - val_precision_1: 0.9107 - val_recall_1: 0.9117 - val_true_positives_1: 5775.0000\n",
      "Epoch 7/25\n",
      "27664/27664 [==============================] - 69s 3ms/step - loss: 0.0441 - accuracy: 0.9881 - precision_1: 0.9849 - recall_1: 0.9890 - true_positives_1: 12496.0000 - val_loss: 0.4753 - val_accuracy: 0.9190 - val_precision_1: 0.9011 - val_recall_1: 0.9245 - val_true_positives_1: 5856.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1d935276a88>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "batch_size = 100\n",
    "epochs = 25\n",
    "model.fit(train_X, train_y, batch_size=batch_size, epochs=epochs, validation_data=(val_X, val_y), callbacks=[saveBestModel, earlyStopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stops in the Epoch 6 out of 25, this is thanks to the validation set, that prevents us to overfit the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model results with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'accuracy', 'precision_1', 'recall_1', 'true_positives_1']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13832/13832 [==============================] - 7s 482us/step\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy, precision, recall, true_positives = model.evaluate(test_X, test_y, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_pr=precision*recall\n",
    "sum_pr=precision+recall\n",
    "div=mult_pr/sum_pr\n",
    "f1_score=2*div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss, Accuracy, Precision, Recall and F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.43703812065799846\n",
      "Accuracy: 0.9235829710960388\n",
      "Precision: 0.9090211987495422\n",
      "Recall: 0.9273751974105835\n",
      "f1 score: 0.9181064778862218\n",
      "True positives: 5925.0\n"
     ]
    }
   ],
   "source": [
    "print('Loss:',loss)\n",
    "print('Accuracy:',accuracy)\n",
    "print('Precision:',precision)\n",
    "print('Recall:',recall)\n",
    "print('f1 score:',f1_score)\n",
    "print('True positives:',true_positives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract FalsePositives and FalseNegatives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first get the list of predictions. In the confusion matrix it can be observed that the number of True Positives is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = model.predict_classes(test_X, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6850,  593],\n",
       "       [ 464, 5925]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a function to compare the predicted values to the actual values and extract the FalsePositives and FalseNegatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFP_FN_lists(test_X, test_y, pred_y):\n",
    "    FP_text = []\n",
    "    FP_index = []\n",
    "    FN_text = []\n",
    "    FN_index = []\n",
    "    for i in range(len(test_y)):\n",
    "        if(pred_y[i]==1 and test_y[test_y.index[i]]==0):\n",
    "            FP_text.append(test['headline'][test_y.index[i]])\n",
    "            FP_index.append(test_y.index[i])\n",
    "        elif(pred_y[i]==0 and test_y[test_y.index[i]]==1):\n",
    "            FN_text.append(test['headline'][test_y.index[i]])\n",
    "            FN_index.append(test_y.index[i])\n",
    "            \n",
    "    return FP_text,FP_index,FN_text,FN_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Returns 2 dataframes, one with all the False Positives and one with all the False Negatives'''\n",
    "def getFP_FN(test_X, test_y, pred_y):\n",
    "    FP_text,FP_index,FN_text,FN_index = getFP_FN_lists(test_X, test_y, pred_y)\n",
    "    d_FP = {'FP_text':FP_text,'FP_index':FP_index}\n",
    "    df_FP = pd.DataFrame(d_FP)\n",
    "    d_FN = {'FN_text':FN_text,'FN_index':FN_index}\n",
    "    df_FN = pd.DataFrame(d_FN)\n",
    "    \n",
    "    return df_FP,df_FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get the FPs and FNs as DataFrames and store them to CSVs\n",
    "df_FP,df_FN = getFP_FN(test_X, test_y, pred_y)\n",
    "df_FP.to_csv('FP.csv', index=True)\n",
    "df_FN.to_csv('FN.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
