{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM with validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, CuDNNLSTM, Embedding, Dropout, Activation, Flatten, Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model, Sequential\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.layers import LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55328\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  is_sarcastic\n",
       "0  former versace store clerk sues over secret 'b...             0\n",
       "1  the 'roseanne' revival catches up to our thorn...             0\n",
       "2  mom starting to fear son's web series closest ...             1\n",
       "3  boehner just wants wife to listen, not come up...             1\n",
       "4  j.k. rowling wishes snape happy birthday in th...             0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_json(\"./data/Sarcasm_Headlines_Dataset.json\", lines=True)\n",
    "df2 = pd.read_json(\"./data/Sarcasm_Headlines_Dataset_v2.json\", lines=True)\n",
    "# re-order attibute columns in df2\n",
    "df2 = df2[['article_link','headline','is_sarcastic']]\n",
    "df = pd.concat([df1, df2], axis=0)\n",
    "df = df.drop(['article_link'], axis=1)\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset the index as we have merged two different indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.953368999421631\n",
      "2\n",
      "151\n"
     ]
    }
   ],
   "source": [
    "df['len'] = df['headline'].apply(lambda x: len(x.split(\" \")))\n",
    "print(df['len'].mean())\n",
    "print(min(df['len']))\n",
    "print(max(df['len']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data in train, test and val\n",
    "50% for train, 25% for test, 25% for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41496, 3)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size=0.25)\n",
    "print(train.shape)\n",
    "train, val = train_test_split(train, test_size=0.33333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (27664, 3)\n",
      "test: (13832, 3)\n",
      "val: (13832, 3)\n"
     ]
    }
   ],
   "source": [
    "print('train:',train.shape)\n",
    "print('test:',test.shape)\n",
    "print('val:',val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize\n",
    "Fit the tokenizer only on the text of training data.\n",
    "Then, we use that same tokenizer to transform the texts of train, val and test sets to sequences of integers.\n",
    "\n",
    "It's possible to fit on the entire data. But it's probably a better idea to reserve a token for \"unknown\" words (oov_token=True), for the cases when you find new test data with words your model has never seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000 # max num words\n",
    "maxlen = 25 # we could also try 151\n",
    "embedding_size = 200\n",
    "\n",
    "# create the tokenizer with the maximum number of words to keep, \n",
    "# based on word frequency. \n",
    "# Only the most common num_words-1 words will be kept.\n",
    "tokenizer = Tokenizer(num_words=max_features, oov_token = True)\n",
    "\n",
    "# fit the tokenizer on the headlines\n",
    "tokenizer.fit_on_texts(list(train['headline']))\n",
    "\n",
    "# Transforms each text in texts to a sequence of integers.\n",
    "train_X = tokenizer.texts_to_sequences(train['headline'])\n",
    "test_X = tokenizer.texts_to_sequences(test['headline'])\n",
    "val_X = tokenizer.texts_to_sequences(val['headline'])\n",
    "\n",
    "# transforms a list of num_samples sequences (lists of integers)\n",
    "# into a 2D Numpy array of shape (num_samples, num_timesteps).\n",
    "train_X = pad_sequences(train_X, maxlen = maxlen)\n",
    "test_X = pad_sequences(test_X, maxlen = maxlen)\n",
    "val_X = pad_sequences(val_X, maxlen = maxlen)\n",
    "\n",
    "train_y = train['is_sarcastic']\n",
    "test_y = test['is_sarcastic']\n",
    "val_y = val['is_sarcastic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load glove embedding set, construct embedding matrix for words in word_index:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elsas\\Anaconda3\\envs\\TFM\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3254: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "# load embeddings\n",
    "EMBEDDING_FILE = './embeddings/glove.6B.200d.txt'\n",
    "\n",
    "def get_coefs(word,*arr): \n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "# first, build index mapping words in the embeddings set\n",
    "# to their embedding vector\n",
    "embeddings_index = {}\n",
    "with open(EMBEDDING_FILE, encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = get_coefs(*line.split(\" \"))\n",
    "        embeddings_index[word] = coefs\n",
    "            \n",
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "\n",
    "# Random embedding vector for unknown words.\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embedding_size))\n",
    "# prepare embedding matrix\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: \n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: \n",
    "        # words not found in embedding index will be random\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Model\n",
    "Model Parameters:\n",
    "\n",
    "- **Activation Function**: I have used ReLU as the activation function. ReLU is a non-linear activation function, which helps complex relationships in the data to be captured by the model.\n",
    "\n",
    "- **Optimiser**: We use adam optimiser, which is an adaptive learning rate optimiser.\n",
    "\n",
    "- **Loss function**: We will train a network to output a probability over the 2 classes using Sigmoid Loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model structure\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_size, weights = [embedding_matrix]))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences = True)))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(40, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(20, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',keras.metrics.Precision(), keras.metrics.Recall(), keras.metrics.TruePositives()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the best model and early stopping\n",
    "To prevent the model from overfitting I have enabled early stopping.\n",
    "\n",
    "Early stopping is a method that allows us to specify an arbitrary large number of training epochs and stop training once the model performance stops improving on a hold out/validation dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model after every epoch.\n",
    "saveBestModel = keras.callbacks.ModelCheckpoint('./model/best_model.hdf5', monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "# Stop training when a monitored quantity has stopped improving.\n",
    "earlyStopping = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elsas\\Anaconda3\\envs\\TFM\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27664 samples, validate on 13832 samples\n",
      "Epoch 1/25\n",
      "27664/27664 [==============================] - 52s 2ms/step - loss: 0.5504 - accuracy: 0.6950 - precision_1: 0.6927 - recall_1: 0.6068 - true_positives_1: 7729.0000 - val_loss: 0.3134 - val_accuracy: 0.8643 - val_precision_1: 0.8371 - val_recall_1: 0.8747 - val_true_positives_1: 5555.0000\n",
      "Epoch 2/25\n",
      "  100/27664 [..............................] - ETA: 44s - loss: 0.4303 - accuracy: 0.8400 - precision_1: 0.7917 - recall_1: 0.8636 - true_positives_1: 38.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elsas\\Anaconda3\\envs\\TFM\\lib\\site-packages\\keras\\callbacks\\callbacks.py:707: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27664/27664 [==============================] - 50s 2ms/step - loss: 0.2931 - accuracy: 0.8951 - precision_1: 0.8814 - recall_1: 0.8922 - true_positives_1: 11364.0000 - val_loss: 0.2470 - val_accuracy: 0.8989 - val_precision_1: 0.8906 - val_recall_1: 0.8892 - val_true_positives_1: 5647.0000\n",
      "Epoch 3/25\n",
      "27664/27664 [==============================] - 51s 2ms/step - loss: 0.1749 - accuracy: 0.9414 - precision_1: 0.9365 - recall_1: 0.9362 - true_positives_1: 11925.0000 - val_loss: 0.2385 - val_accuracy: 0.9163 - val_precision_1: 0.9054 - val_recall_1: 0.9131 - val_true_positives_1: 5799.0000\n",
      "Epoch 4/25\n",
      "27664/27664 [==============================] - 51s 2ms/step - loss: 0.1079 - accuracy: 0.9657 - precision_1: 0.9629 - recall_1: 0.9626 - true_positives_1: 12261.0000 - val_loss: 0.2707 - val_accuracy: 0.9202 - val_precision_1: 0.9209 - val_recall_1: 0.9038 - val_true_positives_1: 5740.0000\n",
      "Epoch 5/25\n",
      "27664/27664 [==============================] - 52s 2ms/step - loss: 0.0720 - accuracy: 0.9773 - precision_1: 0.9755 - recall_1: 0.9752 - true_positives_1: 12421.0000 - val_loss: 0.3114 - val_accuracy: 0.9245 - val_precision_1: 0.9070 - val_recall_1: 0.9309 - val_true_positives_1: 5912.0000\n",
      "Epoch 6/25\n",
      "27664/27664 [==============================] - 51s 2ms/step - loss: 0.0462 - accuracy: 0.9858 - precision_1: 0.9850 - recall_1: 0.9841 - true_positives_1: 12535.0000 - val_loss: 0.4279 - val_accuracy: 0.9261 - val_precision_1: 0.9370 - val_recall_1: 0.8995 - val_true_positives_1: 5713.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x25c697fef08>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "batch_size = 100\n",
    "epochs = 25\n",
    "model.fit(train_X, train_y, batch_size=batch_size, epochs=epochs, validation_data=(val_X, val_y), callbacks=[saveBestModel, earlyStopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stops in the Epoch 6 out of 25, this is thanks to the validation set, that prevents us to overfit the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model results with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'accuracy', 'precision_1', 'recall_1', 'true_positives_1']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13832/13832 [==============================] - 5s 364us/step\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy, precision, recall, true_positives = model.evaluate(test_X, test_y, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_pr=precision*recall\n",
    "sum_pr=precision+recall\n",
    "div=mult_pr/sum_pr\n",
    "f1_score=2*div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss, Accuracy, Precision, Recall and F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4296985449815603\n",
      "Accuracy: 0.927342414855957\n",
      "Precision: 0.9288157820701599\n",
      "Recall: 0.9094098806381226\n",
      "f1 score: 0.9190103986066201\n",
      "True positives: 5702.0\n"
     ]
    }
   ],
   "source": [
    "print('Loss:',loss)\n",
    "print('Accuracy:',accuracy)\n",
    "print('Precision:',precision)\n",
    "print('Recall:',recall)\n",
    "print('f1 score:',f1_score)\n",
    "print('True positives:',true_positives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract FalsePositives and FalseNegatives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first get the list of predictions. In the confusion matrix it can be observed that the number of True Positives is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = model.predict_classes(test_X, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7125,  437],\n",
       "       [ 568, 5702]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38926    0\n",
       "8528     1\n",
       "43902    1\n",
       "45270    1\n",
       "35418    1\n",
       "        ..\n",
       "51091    0\n",
       "50344    1\n",
       "25426    0\n",
       "31066    0\n",
       "16062    0\n",
       "Name: is_sarcastic, Length: 13832, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[test_y.index[7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'woman quickly cycles through non-threatening voice inflections before expressing concern'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['headline'][test_y.index[7]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a function to compare the predicted values to the actual values and extract the FalsePositives and FalseNegatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFP_FN_lists(test_X, test_y, pred_y):\n",
    "    FP_text = []\n",
    "    FP_index = []\n",
    "    FN_text = []\n",
    "    FN_index = []\n",
    "    for i in range(len(test_y)):\n",
    "        if(pred_y[i]==1 and test_y[test_y.index[i]]==0):\n",
    "            FP_text.append(test['headline'][test_y.index[i]])\n",
    "            FP_index.append(test_y.index[i])\n",
    "        elif(pred_y[i]==0 and test_y[test_y.index[i]]==1):\n",
    "            FN_text.append(test['headline'][test_y.index[i]])\n",
    "            FN_index.append(test_y.index[i])\n",
    "            \n",
    "    return FP_text,FP_index,FN_text,FN_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Returns 2 dataframes, one with all the False Positives and one with all the False Negatives'''\n",
    "def getFP_FN(test_X, test_y, pred_y):\n",
    "    FP_text,FP_index,FN_text,FN_index = getFP_FN_lists(test_X, test_y, pred_y)\n",
    "    d_FP = {'FP_text':FP_text,'FP_index':FP_index}\n",
    "    df_FP = pd.DataFrame(d_FP)\n",
    "    d_FN = {'FN_text':FN_text,'FN_index':FN_index}\n",
    "    df_FN = pd.DataFrame(d_FN)\n",
    "    \n",
    "    return df_FP,df_FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FP,df_FN = getFP_FN(test_X, test_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FP_text</th>\n",
       "      <th>FP_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>couple is trying to make personal shark cages ...</td>\n",
       "      <td>31642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>atlantic city casino can regulate waitresses' ...</td>\n",
       "      <td>46746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hollywood talent agency ditches usual oscar pa...</td>\n",
       "      <td>43427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bikini-clad britney spends spring break with h...</td>\n",
       "      <td>4622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fine-tuning our tour program</td>\n",
       "      <td>1256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>dog with skin condition has a strange past</td>\n",
       "      <td>45570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>brian williams cancels planned 'letterman' app...</td>\n",
       "      <td>41823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>dad defends son's cruella halloween costume fr...</td>\n",
       "      <td>15427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>ferocious rat refuses to let hungry snake stea...</td>\n",
       "      <td>35589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>air force will no longer require 'so help me g...</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>437 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               FP_text  FP_index\n",
       "0    couple is trying to make personal shark cages ...     31642\n",
       "1    atlantic city casino can regulate waitresses' ...     46746\n",
       "2    hollywood talent agency ditches usual oscar pa...     43427\n",
       "3    bikini-clad britney spends spring break with h...      4622\n",
       "4                         fine-tuning our tour program      1256\n",
       "..                                                 ...       ...\n",
       "432         dog with skin condition has a strange past     45570\n",
       "433  brian williams cancels planned 'letterman' app...     41823\n",
       "434  dad defends son's cruella halloween costume fr...     15427\n",
       "435  ferocious rat refuses to let hungry snake stea...     35589\n",
       "436  air force will no longer require 'so help me g...       119\n",
       "\n",
       "[437 rows x 2 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FN_text</th>\n",
       "      <th>FN_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u.s. economy continues campaigning for barack ...</td>\n",
       "      <td>7504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>naacp calls for more diversity in police lineups</td>\n",
       "      <td>12736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>morning after morning after pill re-impregnate...</td>\n",
       "      <td>1512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shocking 'game of thrones' finale concludes wi...</td>\n",
       "      <td>17975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>report: hey, stephen tobolowsky is in this!</td>\n",
       "      <td>38822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>photo of crying father a lasting symbol of eco...</td>\n",
       "      <td>29994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>queen elizabeth to think mainly about her appr...</td>\n",
       "      <td>14962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>white house releases moving statement honoring...</td>\n",
       "      <td>50403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>new law determines bullets no longer responsib...</td>\n",
       "      <td>26499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>there no way tv character could actually affor...</td>\n",
       "      <td>26907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>568 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               FN_text  FN_index\n",
       "0    u.s. economy continues campaigning for barack ...      7504\n",
       "1     naacp calls for more diversity in police lineups     12736\n",
       "2    morning after morning after pill re-impregnate...      1512\n",
       "3    shocking 'game of thrones' finale concludes wi...     17975\n",
       "4          report: hey, stephen tobolowsky is in this!     38822\n",
       "..                                                 ...       ...\n",
       "563  photo of crying father a lasting symbol of eco...     29994\n",
       "564  queen elizabeth to think mainly about her appr...     14962\n",
       "565  white house releases moving statement honoring...     50403\n",
       "566  new law determines bullets no longer responsib...     26499\n",
       "567  there no way tv character could actually affor...     26907\n",
       "\n",
       "[568 rows x 2 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
