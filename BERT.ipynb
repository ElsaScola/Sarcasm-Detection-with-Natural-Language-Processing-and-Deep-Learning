{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sarcasm Detection: BERT\n",
    "\n",
    "## Author: Elsa Scola Martín\n",
    "### Objective:\n",
    "Using the dataset [News Headlines Dataset For Sarcasm Detection](https://www.kaggle.com/rmisra/news-headlines-dataset-for-sarcasm-detection) created by [Rishabh Misra and Prahal Arora](https://arxiv.org/abs/1908.07414), the goal of this notebook is to illustrate the implementation of BERT for sarcasm detection.\n",
    "\n",
    "### What is done in the Notebook: \n",
    "- Load the required dependencies\n",
    "- Define helper functions\n",
    "- Load BERT from the Tensorflow Hub\n",
    "- Load CSV files containing data\n",
    "- Load tokenizer\n",
    "- Text encoding\n",
    "- Build model\n",
    "- Save the best model and early stopping\n",
    "- Fit the model\n",
    "- Evaluate model results with test data\n",
    "- Extract False Positives and False Negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O3i4OtaOSSzX"
   },
   "outputs": [],
   "source": [
    "# We will use the official tokenization script created by the Google team\n",
    "!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "MXUai2EiSnCQ",
    "outputId": "87a31a3c-bc1d-420b-fe02-de36d078a01e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/2c/8df20f3ac6c22ac224fff307ebc102818206c53fc454ecd37d8ac2060df5/sentencepiece-0.1.86-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 5.0MB/s \n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.86\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "3Xtjt9vFSSzs",
    "outputId": "e95a1821-2cbe-44f8-a299-b6837ed04b5e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow_hub as hub\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "import keras\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V4X7fcjvSSz-"
   },
   "source": [
    "### Define Helper Functions\n",
    "[Source](https://www.kaggle.com/xhlulu/disaster-nlp-keras-bert-using-tfhub) of helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vUeYQc5vSS0A"
   },
   "outputs": [],
   "source": [
    "def bert_encode(texts, tokenizer, max_len=160):\n",
    "    all_tokens = []\n",
    "    all_masks = []\n",
    "    all_segments = []\n",
    "    \n",
    "    for text in texts:\n",
    "        text = tokenizer.tokenize(text)\n",
    "            \n",
    "        text = text[:max_len-2]\n",
    "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
    "        pad_len = max_len - len(input_sequence)\n",
    "        \n",
    "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
    "        tokens += [0] * pad_len\n",
    "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
    "        segment_ids = [0] * max_len\n",
    "        \n",
    "        all_tokens.append(tokens)\n",
    "        all_masks.append(pad_masks)\n",
    "        all_segments.append(segment_ids)\n",
    "    \n",
    "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dREk4XJzSS0M"
   },
   "outputs": [],
   "source": [
    "def build_model(bert_layer, max_len=160):\n",
    "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "    segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
    "\n",
    "    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "    clf_output = sequence_output[:, 0, :]\n",
    "    out = Dense(1, activation='sigmoid')(clf_output)\n",
    "    \n",
    "    model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
    "    model.compile(Adam(lr=2e-6), loss='binary_crossentropy', metrics=['accuracy',keras.metrics.Precision(), keras.metrics.Recall(), keras.metrics.TruePositives()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bhYaMiS8SS0X"
   },
   "source": [
    "### Load BERT from the Tensorflow Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "eNMSjzwASS0Z",
    "outputId": "f8515330-393c-46c0-a039-1e24bca144c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.9 s, sys: 4.22 s, total: 25.1 s\n",
      "Wall time: 34.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "module_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\"\n",
    "bert_layer = hub.KerasLayer(module_url, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "9FOJrSKc5kwN",
    "outputId": "29644c93-7d43-4d97-efb8-8cd9969031e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Load the Drive helper and mount\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CSV files containing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oAazwd7rSS0k"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/content/drive/My Drive/TFMColab/train.csv\")\n",
    "val = pd.read_csv(\"/content/drive/My Drive/TFMColab/val.csv\")\n",
    "test = pd.read_csv(\"/content/drive/My Drive/TFMColab/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nVMoBrN_SS1A"
   },
   "outputs": [],
   "source": [
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lKprUPE_SS1I"
   },
   "outputs": [],
   "source": [
    "train_input = bert_encode(train.headline.values, tokenizer, max_len = 160)\n",
    "test_input = bert_encode(test.headline.values, tokenizer, max_len = 160)\n",
    "val_input = bert_encode(val.headline.values, tokenizer, max_len = 160)\n",
    "\n",
    "train_labels = train.is_sarcastic.values\n",
    "test_labels = test.is_sarcastic.values\n",
    "val_labels = val.is_sarcastic.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GIVuBBuaSS1R"
   },
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "colab_type": "code",
    "id": "w-5pXP86SS1T",
    "outputId": "f05404fb-c60e-4e0b-b29f-b3b3c183fabd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_word_ids (InputLayer)     [(None, 160)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 160)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 160)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer (KerasLayer)        [(None, 1024), (None 335141889   input_word_ids[0][0]             \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 1024)]       0           keras_layer[0][1]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            1025        tf_op_layer_strided_slice[0][0]  \n",
      "==================================================================================================\n",
      "Total params: 335,142,914\n",
      "Trainable params: 335,142,913\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(bert_layer, max_len = 160)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the best model and early stopping\n",
    "\n",
    "To prevent the model from overfitting early stopping has been enabled.\n",
    "\n",
    "Early stopping is a method that allows us to specify an arbitrary large number of training epochs and stop training once the model performance stops improving on a hold out/validation dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "2Mj-xJTW8h_N",
    "outputId": "1a0d4c62-0fe0-4a2b-b6dc-995872a7b3ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "# Save the model after every epoch.\n",
    "saveBestModel = ModelCheckpoint('best_model.hdf5', monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "# Stop training when a monitored quantity has stopped improving.\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "colab_type": "code",
    "id": "dtDjzJ_PSS1c",
    "outputId": "2bf3826f-42be-4ae6-ad74-30f6361ad3c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "998/998 [==============================] - ETA: 0s - loss: 0.3128 - accuracy: 0.8656 - precision_1: 0.7943 - recall_1: 0.8040 - true_positives_1: 4351.9478WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "998/998 [==============================] - 1164s 1s/step - loss: 0.3128 - accuracy: 0.8656 - precision_1: 0.7943 - recall_1: 0.8040 - true_positives_1: 4351.9478 - val_loss: 0.2525 - val_accuracy: 0.8923 - val_precision_1: 0.8473 - val_recall_1: 0.8530 - val_true_positives_1: 9121.3428\n",
      "Epoch 2/10\n",
      "998/998 [==============================] - ETA: 0s - loss: 0.1568 - accuracy: 0.9407 - precision_1: 0.8746 - recall_1: 0.8763 - true_positives_1: 14150.2217WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "998/998 [==============================] - 1162s 1s/step - loss: 0.1568 - accuracy: 0.9407 - precision_1: 0.8746 - recall_1: 0.8763 - true_positives_1: 14150.2217 - val_loss: 0.2318 - val_accuracy: 0.9077 - val_precision_1: 0.8913 - val_recall_1: 0.8915 - val_true_positives_1: 19195.9785\n",
      "Epoch 3/10\n",
      "998/998 [==============================] - ETA: 0s - loss: 0.0765 - accuracy: 0.9748 - precision_1: 0.9061 - recall_1: 0.9046 - true_positives_1: 24410.8574WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "998/998 [==============================] - 1162s 1s/step - loss: 0.0765 - accuracy: 0.9748 - precision_1: 0.9061 - recall_1: 0.9046 - true_positives_1: 24410.8574 - val_loss: 0.2467 - val_accuracy: 0.9204 - val_precision_1: 0.9162 - val_recall_1: 0.9159 - val_true_positives_1: 29651.2305\n",
      "Epoch 4/10\n",
      "998/998 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.9947 - precision_1: 0.9254 - recall_1: 0.9258 - true_positives_1: 34991.8867WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "998/998 [==============================] - 1162s 1s/step - loss: 0.0213 - accuracy: 0.9947 - precision_1: 0.9254 - recall_1: 0.9258 - true_positives_1: 34991.8867 - val_loss: 0.2942 - val_accuracy: 0.9147 - val_precision_1: 0.9333 - val_recall_1: 0.9332 - val_true_positives_1: 40326.1055\n",
      "Epoch 5/10\n",
      "998/998 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9994 - precision_1: 0.9396 - recall_1: 0.9389 - true_positives_1: 45685.9336WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "998/998 [==============================] - 1161s 1s/step - loss: 0.0047 - accuracy: 0.9994 - precision_1: 0.9396 - recall_1: 0.9389 - true_positives_1: 45685.9336 - val_loss: 0.3654 - val_accuracy: 0.9175 - val_precision_1: 0.9447 - val_recall_1: 0.9439 - val_true_positives_1: 51022.7852\n"
     ]
    }
   ],
   "source": [
    "train_history = model.fit(\n",
    "    train_input, train_labels,\n",
    "    validation_data=(val_input, val_labels),\n",
    "    epochs=10,\n",
    "    batch_size=20,\n",
    "    callbacks=[saveBestModel, earlyStopping]\n",
    ")\n",
    "\n",
    "#model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fdsWL-x59ia2"
   },
   "source": [
    "### Evaluate model results with test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qNvGubBAd15h"
   },
   "source": [
    "Results were obtained by using the 'predict' function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ILZy1TbvSS1m"
   },
   "outputs": [],
   "source": [
    "test_pred = model.predict(test_input)\n",
    "test_pred = test_pred.round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X4ZQXjErdbJ6"
   },
   "outputs": [],
   "source": [
    "recall = metrics.recall_score(test_labels,test_pred)\n",
    "precision = metrics.precision_score(test_labels,test_pred)\n",
    "f1_score = metrics.f1_score(test_labels,test_pred)\n",
    "accuracy = metrics.accuracy_score(test_labels,test_pred)\n",
    "loss = metrics.log_loss(test_labels,test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "colab_type": "code",
    "id": "dfNM2QziiTg3",
    "outputId": "cbd1024f-0834-40f9-9b67-7fab96fc2072"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.9443963599750527\n",
      "Accuracy: 0.9147517979301877\n",
      "Precision: 0.9244851258581236\n",
      "Recall: 0.8938053097345132\n",
      "f1 score: 0.9088863892013498\n"
     ]
    }
   ],
   "source": [
    "print('Loss:',loss)\n",
    "print('Accuracy:',accuracy)\n",
    "print('Precision:',precision)\n",
    "print('Recall:',recall)\n",
    "print('f1 score:',f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "bmeczjWXeCvo",
    "outputId": "ae8edfd9-0fed-4425-e049-7c4acc81d7ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohens kappa: 0.828837\n",
      "ROC AUC: 0.913781\n",
      "[[2791  198]\n",
      " [ 288 2424]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(test_labels,test_pred)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(test_labels,test_pred)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(test_labels,test_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "80sBVHbPiaSv"
   },
   "source": [
    "### Extract False Positives and False Negatives\n",
    "\n",
    "False Positives and False Negatives are stored in a CSV file for posterior analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IoQs0Yd2ibf5"
   },
   "outputs": [],
   "source": [
    "def getFP_FN_lists(test_X, test_y, pred_y):\n",
    "    FP_text = []\n",
    "    FP_index = []\n",
    "    FN_text = []\n",
    "    FN_index = []\n",
    "    for i in range(len(test_y)):\n",
    "        if(pred_y[i]==1 and test_y[test_y.index[i]]==0):\n",
    "            FP_text.append(test['headline'][test_y.index[i]])\n",
    "            FP_index.append(test_y.index[i])\n",
    "        elif(pred_y[i]==0 and test_y[test_y.index[i]]==1):\n",
    "            FN_text.append(test['headline'][test_y.index[i]])\n",
    "            FN_index.append(test_y.index[i])\n",
    "            \n",
    "    return FP_text,FP_index,FN_text,FN_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fi9mx_hHj6UN"
   },
   "outputs": [],
   "source": [
    "'''Returns 2 dataframes, one with all the False Positives and one with all the False Negatives'''\n",
    "def getFP_FN(test_X, test_y, pred_y):\n",
    "    FP_text,FP_index,FN_text,FN_index = getFP_FN_lists(test_X, test_y, pred_y)\n",
    "    d_FP = {'FP_text':FP_text,'FP_index':FP_index}\n",
    "    df_FP = pd.DataFrame(d_FP)\n",
    "    d_FN = {'FN_text':FN_text,'FN_index':FN_index}\n",
    "    df_FN = pd.DataFrame(d_FN)\n",
    "    \n",
    "    return df_FP,df_FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gTyuTkRMlW1d"
   },
   "outputs": [],
   "source": [
    "# We get the FPs and FNs as DataFrames and store them to CSVs\n",
    "df_FP,df_FN = getFP_FN(test['headline'], test['is_sarcastic'],test_pred)\n",
    "df_FP.to_csv('bert_FP.csv', index=True)\n",
    "df_FN.to_csv('bert_FN.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
