{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import codecs\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from chardet import detect\n",
    "import keras\n",
    "from keras_radam import RAdam\n",
    "from keras import backend as K\n",
    "from keras_bert import load_trained_model_from_checkpoint\n",
    "import codecs\n",
    "from keras_bert import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 128\n",
    "BATCH_SIZE = 50\n",
    "EPOCHS = 7\n",
    "LR = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Path to the pre trained model of BERT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download from [here](https://github.com/google-research/bert)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_path = 'uncased_L-12_H-768_A-12'\n",
    "config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
    "checkpoint_path = os.path.join(pretrained_path, 'bert_model.ckpt')\n",
    "vocab_path = os.path.join(pretrained_path, 'vocab.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Pretrained BERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_trained_model_from_checkpoint(\n",
    "      config_path,\n",
    "      checkpoint_path,\n",
    "      training=True,\n",
    "      trainable=True,\n",
    "      seq_len=SEQ_LEN,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input-Token (InputLayer)        (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Segment (InputLayer)      (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token (TokenEmbedding [(None, 128, 768), ( 23440896    Input-Token[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Segment (Embedding)   (None, 128, 768)     1536        Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token-Segment (Add)   (None, 128, 768)     0           Embedding-Token[0][0]            \n",
      "                                                                 Embedding-Segment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Position (PositionEmb (None, 128, 768)     98304       Embedding-Token-Segment[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Dropout (Dropout)     (None, 128, 768)     0           Embedding-Position[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Norm (LayerNormalizat (None, 128, 768)     1536        Embedding-Dropout[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     2362368     Embedding-Norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-1-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     0           Embedding-Norm[0][0]             \n",
      "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-1-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-1-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-1-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-1-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-2-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-1-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-2-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-2-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-2-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-2-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-3-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-2-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-3-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-3-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-3-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-3-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-4-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-3-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-4-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-4-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-4-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-4-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-5-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-4-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-5-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-5-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-5-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-5-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-5-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-6-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-5-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-6-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-6-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-6-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-6-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-6-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-7-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-6-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-7-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-7-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-7-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-7-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-7-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-8-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-7-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-8-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-8-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-8-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-8-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-8-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-9-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-8-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-9-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-9-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-9-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-9-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-9-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-9-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Dropout  (None, 128, 768)     0           Encoder-10-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Add (Add (None, 128, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
      "                                                                 Encoder-10-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-10-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-10-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-10-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Dropout  (None, 128, 768)     0           Encoder-11-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Add (Add (None, 128, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
      "                                                                 Encoder-11-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-11-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-11-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-11-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Dropout  (None, 128, 768)     0           Encoder-12-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Add (Add (None, 128, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
      "                                                                 Encoder-12-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-12-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "MLM-Dense (Dense)               (None, 128, 768)     590592      Encoder-12-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "MLM-Norm (LayerNormalization)   (None, 128, 768)     1536        MLM-Dense[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Extract (Extract)               (None, 768)          0           Encoder-12-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "MLM-Sim (EmbeddingSimilarity)   (None, 128, 30522)   30522       MLM-Norm[0][0]                   \n",
      "                                                                 Embedding-Token[0][1]            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Masked (InputLayer)       (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NSP-Dense (Dense)               (None, 768)          590592      Extract[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "MLM (Masked)                    (None, 128, 30522)   0           MLM-Sim[0][0]                    \n",
      "                                                                 Input-Masked[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "NSP (Dense)                     (None, 2)            1538        NSP-Dense[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 109,811,516\n",
      "Trainable params: 109,811,516\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting token dictionary from vocab of pretrained model to refer for input we will be using.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dict = {}\n",
    "with codecs.open(vocab_path, 'r', 'utf8') as reader:\n",
    "    for line in reader:\n",
    "        token = line.strip()\n",
    "        token_dict[token] = len(token_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55328\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  is_sarcastic\n",
       "0  former versace store clerk sues over secret 'b...             0\n",
       "1  the 'roseanne' revival catches up to our thorn...             0\n",
       "2  mom starting to fear son's web series closest ...             1\n",
       "3  boehner just wants wife to listen, not come up...             1\n",
       "4  j.k. rowling wishes snape happy birthday in th...             0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_json(\"./data/Sarcasm_Headlines_Dataset.json\", lines=True)\n",
    "df2 = pd.read_json(\"./data/Sarcasm_Headlines_Dataset_v2.json\", lines=True)\n",
    "# re-order attibute columns in df2\n",
    "df2 = df2[['article_link','headline','is_sarcastic']]\n",
    "df = pd.concat([df1, df2], axis=0)\n",
    "df = df.drop(['article_link'], axis=1)\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset the index as we have merged two different indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28503\n"
     ]
    }
   ],
   "source": [
    "df.sort_values(\"headline\", inplace = True)\n",
    "df.drop_duplicates(subset =\"headline\", \n",
    "                     keep = 'first', inplace = True) \n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Tokenizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(token_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting data into train, test preceded by tokenizing sentences and returning test train data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 5891, 18992,  2387, 29853, 28486, 27419, 20083, 33972, 43953,\n",
       "            26278,\n",
       "            ...\n",
       "            53825, 37989, 46481, 38548,  5184,  6848,  1973, 54774, 30747,\n",
       "            52181],\n",
       "           dtype='int64', length=28503)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28503"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    global tokenizer\n",
    "    indices, sarc_labels = [], []\n",
    "    for i in df.index:\n",
    "        text = df.headline[i]\n",
    "        ids, segments = tokenizer.encode(text, max_len=25)\n",
    "        indices.append(ids)\n",
    "        sarc_label = df.is_sarcastic[i]\n",
    "        sarc_labels.append(sarc_label)\n",
    "    items = list(zip(indices, sarc_labels))\n",
    "\n",
    "    np.random.shuffle(items)\n",
    "    test_items = items[int(0.8*len(items)):]\n",
    "    train_items = items[:int(0.8*len(items))]\n",
    "    indices_test, sarc_labels_test = zip(*test_items)\n",
    "    indices_train, sarc_labels_train = zip(*train_items)\n",
    "    indices_train = np.array(indices_train)\n",
    "    indices_test = np.array(indices_test)\n",
    "    mod_train = indices_train.shape[0] % BATCH_SIZE\n",
    "    mod_test = indices_test.shape[0] % BATCH_SIZE\n",
    "    if mod_train > 0:\n",
    "        indices_train, sarc_labels_train = indices_train[:-mod_train], sarc_labels_train[:-mod_train]\n",
    "    if mod_test > 0:\n",
    "        indices_test, sarc_labels_test = indices_test[:-mod_test], sarc_labels_test[:-mod_test]\n",
    "\n",
    "    return [indices_train, np.zeros_like(indices_train)], np.array(sarc_labels_train),[indices_test, np.zeros_like(indices_test)], np.array(sarc_labels_test)\n",
    "  \n",
    "train_x, train_y, test_x, test_y = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2a189bb0248>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(train_y).value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Extracting layer from pretrained bert model and adding a layer with sigmoid function to classify a binary class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = model.inputs[:2]\n",
    "dense = model.get_layer('NSP-Dense').output\n",
    "outputs = keras.layers.Dense(units=1, activation='sigmoid')(dense)\n",
    "\n",
    "model = keras.models.Model(inputs, outputs)\n",
    "model.compile(\n",
    "  RAdam(learning_rate =LR),\n",
    "  loss='sparse_categorical_crossentropy',\n",
    "  metrics=['sparse_categorical_accuracy'],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
