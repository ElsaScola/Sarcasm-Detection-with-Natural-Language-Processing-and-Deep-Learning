{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "BERT3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3i4OtaOSSzX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We will use the official tokenization script created by the Google team\n",
        "!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXUai2EiSnCQ",
        "colab_type": "code",
        "outputId": "02535350-1f32-4ecd-8aa1-dd5d2ce9e72e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/2c/8df20f3ac6c22ac224fff307ebc102818206c53fc454ecd37d8ac2060df5/sentencepiece-0.1.86-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 3.4MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.86\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Xtjt9vFSSzs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import tensorflow_hub as hub\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "\n",
        "import tokenization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w83sosWLSSz8",
        "colab_type": "text"
      },
      "source": [
        "## Using the original BERT code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4X7fcjvSSz-",
        "colab_type": "text"
      },
      "source": [
        "Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUeYQc5vSS0A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bert_encode(texts, tokenizer, max_len=160):\n",
        "    all_tokens = []\n",
        "    all_masks = []\n",
        "    all_segments = []\n",
        "    \n",
        "    for text in texts:\n",
        "        text = tokenizer.tokenize(text)\n",
        "            \n",
        "        text = text[:max_len-2]\n",
        "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
        "        pad_len = max_len - len(input_sequence)\n",
        "        \n",
        "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
        "        tokens += [0] * pad_len\n",
        "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
        "        segment_ids = [0] * max_len\n",
        "        \n",
        "        all_tokens.append(tokens)\n",
        "        all_masks.append(pad_masks)\n",
        "        all_segments.append(segment_ids)\n",
        "    \n",
        "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dREk4XJzSS0M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(bert_layer, max_len=160):\n",
        "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "    input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
        "    segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
        "\n",
        "    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
        "    clf_output = sequence_output[:, 0, :]\n",
        "    out = Dense(1, activation='sigmoid')(clf_output)\n",
        "    \n",
        "    model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
        "    model.compile(Adam(lr=2e-6), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhYaMiS8SS0X",
        "colab_type": "text"
      },
      "source": [
        "## Load and Preprocess¶"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNMSjzwASS0Z",
        "colab_type": "code",
        "outputId": "a27ca0bd-c35c-42b9-eada-9ec33b7979c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "%%time\n",
        "module_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\"\n",
        "bert_layer = hub.KerasLayer(module_url, trainable=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 22 s, sys: 4.25 s, total: 26.2 s\n",
            "Wall time: 1min 11s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAazwd7rSS0k",
        "colab_type": "code",
        "outputId": "9d87b397-7b28-4042-c9bc-d3da3732e5e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "df1 = pd.read_json(\"Sarcasm_Headlines_Dataset.json\", lines=True)\n",
        "df2 = pd.read_json(\"Sarcasm_Headlines_Dataset_v2.json\", lines=True)\n",
        "# re-order attibute columns in df2\n",
        "df2 = df2[['article_link','headline','is_sarcastic']]\n",
        "df = pd.concat([df1, df2], axis=0)\n",
        "df = df.drop(['article_link'], axis=1)\n",
        "print(len(df))\n",
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55328\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>former versace store clerk sues over secret 'b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mom starting to fear son's web series closest ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>boehner just wants wife to listen, not come up...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            headline  is_sarcastic\n",
              "0  former versace store clerk sues over secret 'b...             0\n",
              "1  the 'roseanne' revival catches up to our thorn...             0\n",
              "2  mom starting to fear son's web series closest ...             1\n",
              "3  boehner just wants wife to listen, not come up...             1\n",
              "4  j.k. rowling wishes snape happy birthday in th...             0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDc8kwlTSS0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.reset_index(inplace=True, drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMPgL4FyTCCB",
        "colab_type": "code",
        "outputId": "d624c9f2-878d-4754-800b-600367460f58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "df.sort_values(\"headline\", inplace = True)\n",
        "df.drop_duplicates(subset =\"headline\", \n",
        "                     keep = 'first', inplace = True) \n",
        "print(len(df))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28503\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMAL3NrTSS03",
        "colab_type": "code",
        "outputId": "ad2e5f53-16e6-467c-b004-884d0aa354b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(df.headline.str.len().max()) # maximum headline has 926 characters\n",
        "\n",
        "index_array = df.headline.str.len() <= 160 # cutting it off at tweet length\n",
        "\n",
        "df = df[index_array]\n",
        "\n",
        "train,test = model_selection.train_test_split(df,test_size = 0.3)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "926\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVMoBrN_SS1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKprUPE_SS1I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_input = bert_encode(train.headline.values, tokenizer, max_len = 160)\n",
        "test_input = bert_encode(test.headline.values, tokenizer, max_len = 160)\n",
        "train_labels = train.is_sarcastic.values\n",
        "test_labels = test.is_sarcastic.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIVuBBuaSS1R",
        "colab_type": "text"
      },
      "source": [
        "### Model: Build, Train, Predict, Validate¶"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-5pXP86SS1T",
        "colab_type": "code",
        "outputId": "621d1f88-c57a-4412-d9af-48c534686c80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "model = build_model(bert_layer, max_len = 160)\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_word_ids (InputLayer)     [(None, 160)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_mask (InputLayer)         [(None, 160)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "segment_ids (InputLayer)        [(None, 160)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer (KerasLayer)        [(None, 1024), (None 335141889   input_word_ids[0][0]             \n",
            "                                                                 input_mask[0][0]                 \n",
            "                                                                 segment_ids[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice (Tens [(None, 1024)]       0           keras_layer[0][1]                \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1)            1025        tf_op_layer_strided_slice[0][0]  \n",
            "==================================================================================================\n",
            "Total params: 335,142,914\n",
            "Trainable params: 335,142,913\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtDjzJ_PSS1c",
        "colab_type": "code",
        "outputId": "b3bba653-094a-4ad4-8c86-2ea8eb15a49a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "train_history = model.fit(\n",
        "    train_input, train_labels,\n",
        "    validation_split=0.1,\n",
        "    epochs=5,\n",
        "    batch_size=20\n",
        ")\n",
        "\n",
        "model.save('model.h5')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "898/898 [==============================] - 1036s 1s/step - loss: 0.3412 - accuracy: 0.8483 - val_loss: 0.2834 - val_accuracy: 0.8787\n",
            "Epoch 2/5\n",
            "898/898 [==============================] - 1034s 1s/step - loss: 0.1698 - accuracy: 0.9339 - val_loss: 0.2438 - val_accuracy: 0.9078\n",
            "Epoch 3/5\n",
            "898/898 [==============================] - 1034s 1s/step - loss: 0.0746 - accuracy: 0.9768 - val_loss: 0.2941 - val_accuracy: 0.8942\n",
            "Epoch 4/5\n",
            "898/898 [==============================] - 1035s 1s/step - loss: 0.0224 - accuracy: 0.9955 - val_loss: 0.3354 - val_accuracy: 0.9098\n",
            "Epoch 5/5\n",
            "898/898 [==============================] - 1034s 1s/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.4189 - val_accuracy: 0.9078\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILZy1TbvSS1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_pred = model.predict(test_input)\n",
        "test_pred = test_pred.round().astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BX0OZRW0SS1t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "024bfd2a-75b5-4787-f755-ec0f4d52189d"
      },
      "source": [
        "metrics.accuracy_score(test_labels,test_pred)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9114516317697976"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCaC3U_jcwld",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0d17d5f6-79ca-485e-8cef-f004dea88f52"
      },
      "source": [
        "metrics.f1_score(test_labels,test_pred)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9068307692307692"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4ZQXjErdbJ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fab5c4b4-9de8-4c4c-f333-924b2e2e1ffa"
      },
      "source": [
        "metrics.recall_score(test_labels,test_pred)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8956965718453683"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfNM2QziiTg3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6a73d0fd-7a44-460f-cacc-0c07a14f7009"
      },
      "source": [
        "metrics.precision_score(test_labels,test_pred)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9182452642073778"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmeczjWXeCvo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "14f30234-f0bc-4ef0-ff92-e7cc3cbfc9f0"
      },
      "source": [
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# kappa\n",
        "kappa = cohen_kappa_score(test_labels,test_pred)\n",
        "print('Cohens kappa: %f' % kappa)\n",
        "# ROC AUC\n",
        "auc = roc_auc_score(test_labels,test_pred)\n",
        "print('ROC AUC: %f' % auc)\n",
        "# confusion matrix\n",
        "matrix = confusion_matrix(test_labels,test_pred)\n",
        "print(matrix)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cohens kappa: 0.822491\n",
            "ROC AUC: 0.910878\n",
            "[[4108  328]\n",
            " [ 429 3684]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80sBVHbPiaSv",
        "colab_type": "text"
      },
      "source": [
        "# Extract FalsePositives and FalseNegatives\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoQs0Yd2ibf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getFP_FN_lists(test_X, test_y, pred_y):\n",
        "    FP_text = []\n",
        "    FP_index = []\n",
        "    FN_text = []\n",
        "    FN_index = []\n",
        "    for i in range(len(test_y)):\n",
        "        if(pred_y[i]==1 and test_y[test_y.index[i]]==0):\n",
        "            FP_text.append(test['headline'][test_y.index[i]])\n",
        "            FP_index.append(test_y.index[i])\n",
        "        elif(pred_y[i]==0 and test_y[test_y.index[i]]==1):\n",
        "            FN_text.append(test['headline'][test_y.index[i]])\n",
        "            FN_index.append(test_y.index[i])\n",
        "            \n",
        "    return FP_text,FP_index,FN_text,FN_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi9mx_hHj6UN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''Returns 2 dataframes, one with all the False Positives and one with all the False Negatives'''\n",
        "def getFP_FN(test_X, test_y, pred_y):\n",
        "    FP_text,FP_index,FN_text,FN_index = getFP_FN_lists(test_X, test_y, pred_y)\n",
        "    d_FP = {'FP_text':FP_text,'FP_index':FP_index}\n",
        "    df_FP = pd.DataFrame(d_FP)\n",
        "    d_FN = {'FN_text':FN_text,'FN_index':FN_index}\n",
        "    df_FN = pd.DataFrame(d_FN)\n",
        "    \n",
        "    return df_FP,df_FN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTyuTkRMlW1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We get the FPs and FNs as DataFrames and store them to CSVs\n",
        "df_FP,df_FN = getFP_FN(test['headline'], test['is_sarcastic'],test_pred)\n",
        "df_FP.to_csv('bert_FP.csv', index=True)\n",
        "df_FN.to_csv('bert_FN.csv', index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}